{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-10-08T04:12:13.749923Z",
     "iopub.status.busy": "2021-10-08T04:12:13.749647Z",
     "iopub.status.idle": "2021-10-08T04:12:13.780354Z",
     "shell.execute_reply": "2021-10-08T04:12:13.779191Z",
     "shell.execute_reply.started": "2021-10-08T04:12:13.749841Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"background-color:#682F2F;font-family:newtimeroman;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\">Customer Segmentation</p>\n",
    "\n",
    "<img src=\"https://github.com/KarnikaKapoor/Files/blob/main/Colorful%20Handwritten%20About%20Me%20Blank%20Education%20Presentation.gif?raw=true\">\n",
    "\n",
    "In this project, I will be performing an unsupervised clustering of data on the customer's records from a groceries firm's database. Customer segmentation is the practice of separating customers into groups that reflect similarities among customers in each cluster. I will divide customers into segments to optimize the significance of each customer to the business. To modify products according to distinct needs and behaviours of the customers. It also helps the business to cater to the concerns of different types of customers.\n",
    "\n",
    "\n",
    "   <a id='top'></a>\n",
    "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
    "<p style=\"background-color:#682F2F;font-family:newtimeroman;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\">TABLE OF CONTENTS</p>   \n",
    "    \n",
    "* [1. IMPORTING LIBRARIES](#1)\n",
    "    \n",
    "* [2. LOADING DATA](#2)\n",
    "    \n",
    "* [3. DATA CLEANING](#3)\n",
    "    \n",
    "* [4. DATA PREPROCESSING](#4)   \n",
    "    \n",
    "* [5. DIMENSIONALITY REDUCTION](#5) \n",
    "      \n",
    "* [6. CLUSTERING](#6)\n",
    "    \n",
    "* [7. EVALUATING MODELS](#7)\n",
    "    \n",
    "* [8. PROFILING](#8)\n",
    "    \n",
    "* [9. CONCLUSION](#9)\n",
    "    \n",
    "* [10. END](#10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "# <p style=\"background-color:#682F2F;font-family:newtimeroman;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\">IMPORTING LIBRARIES</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T04:12:13.782486Z",
     "iopub.status.busy": "2021-10-08T04:12:13.782145Z",
     "iopub.status.idle": "2021-10-08T04:12:15.112632Z",
     "shell.execute_reply": "2021-10-08T04:12:15.111782Z",
     "shell.execute_reply.started": "2021-10-08T04:12:13.782444Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In C:\\Users\\tomst\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\tomst\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\tomst\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In C:\\Users\\tomst\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\tomst\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\tomst\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\tomst\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In C:\\Users\\tomst\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "#Importing the Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt, numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "# <p style=\"background-color:#682F2F;font-family:newtimeroman;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\">LOADING DATA</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T04:12:15.114343Z",
     "iopub.status.busy": "2021-10-08T04:12:15.113716Z",
     "iopub.status.idle": "2021-10-08T04:12:15.171567Z",
     "shell.execute_reply": "2021-10-08T04:12:15.170683Z",
     "shell.execute_reply.started": "2021-10-08T04:12:15.114297Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'../input/customer-personality-analysis/marketing_campaign.csv' does not exist: b'../input/customer-personality-analysis/marketing_campaign.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0afaa86d930c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Loading the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../input/customer-personality-analysis/marketing_campaign.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of datapoints:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'../input/customer-personality-analysis/marketing_campaign.csv' does not exist: b'../input/customer-personality-analysis/marketing_campaign.csv'"
     ]
    }
   ],
   "source": [
    "#Loading the dataset\n",
    "data = pd.read_csv(\"../input/customer-personality-analysis/marketing_campaign.csv\", sep=\"\\t\")\n",
    "print(\"Number of datapoints:\", len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/KarnikaKapoor/Files/blob/main/Colorful%20Handwritten%20About%20Me%20Blank%20Education%20Presentation.png?raw=true\">\n",
    "\n",
    "For more information on the attributes visit [here](https://www.kaggle.com/imakash3011/customer-personality-analysis).\n",
    "\n",
    "<a id=\"3\"></a>\n",
    "# <p style=\"background-color:#682F2F;font-family:newtimeroman;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\">DATA CLEANING</p>\n",
    "\n",
    "\n",
    "**In this section** \n",
    "* Data Cleaning\n",
    "* Feature Engineering \n",
    "\n",
    "In order to, get a full grasp of what steps should I be taking to clean the dataset. \n",
    "Let us have a look at the information in data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T04:12:15.173477Z",
     "iopub.status.busy": "2021-10-08T04:12:15.17321Z",
     "iopub.status.idle": "2021-10-08T04:12:15.198247Z",
     "shell.execute_reply": "2021-10-08T04:12:15.197443Z",
     "shell.execute_reply.started": "2021-10-08T04:12:15.173448Z"
    }
   },
   "outputs": [],
   "source": [
    "#Information on features \n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the above output, we can conclude and note that:**\n",
    "\n",
    "* There are missing values in income\n",
    "* Dt_Customer that indicates the date a customer joined the database is not parsed as DateTime\n",
    "* There are some categorical features in our data frame; as there are some features in dtype: object). So we will need to encode them into numeric forms later. \n",
    "\n",
    "First of all, for the missing values, I am simply going to drop the rows that have missing income values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T04:12:15.199874Z",
     "iopub.status.busy": "2021-10-08T04:12:15.199567Z",
     "iopub.status.idle": "2021-10-08T04:12:15.209802Z",
     "shell.execute_reply": "2021-10-08T04:12:15.208656Z",
     "shell.execute_reply.started": "2021-10-08T04:12:15.199835Z"
    }
   },
   "outputs": [],
   "source": [
    "#To remove the NA values\n",
    "data = data.dropna()\n",
    "print(\"The total number of data-points after removing the rows with missing values are:\", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, I am going to create a feature out of **\"Dt_Customer\"** that indicates the number of days a customer is registered in the firm's database. However, in order to keep it simple, I am taking this value relative to the most recent customer in the record. \n",
    "\n",
    "Thus to get the values I must check the newest and oldest recorded dates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T04:12:15.211499Z",
     "iopub.status.busy": "2021-10-08T04:12:15.211075Z",
     "iopub.status.idle": "2021-10-08T04:12:15.229137Z",
     "shell.execute_reply": "2021-10-08T04:12:15.228054Z",
     "shell.execute_reply.started": "2021-10-08T04:12:15.211459Z"
    }
   },
   "outputs": [],
   "source": [
    "data[\"Dt_Customer\"] = pd.to_datetime(data[\"Dt_Customer\"])\n",
    "dates = []\n",
    "for i in data[\"Dt_Customer\"]:\n",
    "    i = i.date()\n",
    "    dates.append(i)  \n",
    "#Dates of the newest and oldest recorded customer\n",
    "print(\"The newest customer's enrolment date in therecords:\",max(dates))\n",
    "print(\"The oldest customer's enrolment date in the records:\",min(dates))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a feature **(\"Customer_For\")** of the number of days the customers started to shop in the store relative to the last recorded date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T04:12:15.230638Z",
     "iopub.status.busy": "2021-10-08T04:12:15.230408Z",
     "iopub.status.idle": "2021-10-08T04:12:15.250178Z",
     "shell.execute_reply": "2021-10-08T04:12:15.249414Z",
     "shell.execute_reply.started": "2021-10-08T04:12:15.230607Z"
    }
   },
   "outputs": [],
   "source": [
    "#Created a feature \"Customer_For\"\n",
    "days = []\n",
    "d1 = max(dates) #taking it to be the newest customer\n",
    "for i in dates:\n",
    "    delta = d1 - i\n",
    "    days.append(delta)\n",
    "data[\"Customer_For\"] = days\n",
    "data[\"Customer_For\"] = pd.to_numeric(data[\"Customer_For\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will be exploring the unique values in the categorical features to get a clear idea of the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T04:12:15.251554Z",
     "iopub.status.busy": "2021-10-08T04:12:15.251233Z",
     "iopub.status.idle": "2021-10-08T04:12:15.265666Z",
     "shell.execute_reply": "2021-10-08T04:12:15.264597Z",
     "shell.execute_reply.started": "2021-10-08T04:12:15.251514Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Total categories in the feature Marital_Status:\\n\", data[\"Marital_Status\"].value_counts(), \"\\n\")\n",
    "print(\"Total categories in the feature Education:\\n\", data[\"Education\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the next bit, I will be performing the following steps to engineer some new features:**\n",
    "\n",
    "* Extract the **\"Age\"** of a customer by the **\"Year_Birth\"** indicating the birth year of the respective person.\n",
    "* Create another feature **\"Spent\"** indicating the total amount spent by the customer in various categories over the span of two years.\n",
    "* Create another feature **\"Living_With\"** out of **\"Marital_Status\"** to extract the living situation of couples.\n",
    "* Create a feature **\"Children\"** to indicate total children in a household that is, kids and teenagers.\n",
    "* To get further clarity of household, Creating feature indicating **\"Family_Size\"**\n",
    "* Create a feature **\"Is_Parent\"** to indicate parenthood status\n",
    "* Lastly, I will create three categories in the **\"Education\"** by simplifying its value counts.\n",
    "* Dropping some of the redundant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T04:12:15.268669Z",
     "iopub.status.busy": "2021-10-08T04:12:15.268409Z",
     "iopub.status.idle": "2021-10-08T04:12:15.399688Z",
     "shell.execute_reply": "2021-10-08T04:12:15.398865Z",
     "shell.execute_reply.started": "2021-10-08T04:12:15.26864Z"
    }
   },
   "outputs": [],
   "source": [
    "#Feature Engineering\n",
    "#Age of customer today \n",
    "data[\"Age\"] = 2021-data[\"Year_Birth\"]\n",
    "\n",
    "#Total spendings on various items\n",
    "data[\"Spent\"] = data[\"MntWines\"]+ data[\"MntFruits\"]+ data[\"MntMeatProducts\"]+ data[\"MntFishProducts\"]+ data[\"MntSweetProducts\"]+ data[\"MntGoldProds\"]\n",
    "\n",
    "#Deriving living situation by marital status\"Alone\"\n",
    "data[\"Living_With\"]=data[\"Marital_Status\"].replace({\"Married\":\"Partner\", \"Together\":\"Partner\", \"Absurd\":\"Alone\", \"Widow\":\"Alone\", \"YOLO\":\"Alone\", \"Divorced\":\"Alone\", \"Single\":\"Alone\",})\n",
    "\n",
    "#Feature indicating total children living in the household\n",
    "data[\"Children\"]=data[\"Kidhome\"]+data[\"Teenhome\"]\n",
    "\n",
    "#Feature for total members in the householde\n",
    "data[\"Family_Size\"] = data[\"Living_With\"].replace({\"Alone\": 1, \"Partner\":2})+ data[\"Children\"]\n",
    "\n",
    "#Feature pertaining parenthood\n",
    "data[\"Is_Parent\"] = np.where(data.Children> 0, 1, 0)\n",
    "\n",
    "#Segmenting education levels in three groups\n",
    "data[\"Education\"]=data[\"Education\"].replace({\"Basic\":\"Undergraduate\",\"2n Cycle\":\"Undergraduate\", \"Graduation\":\"Graduate\", \"Master\":\"Postgraduate\", \"PhD\":\"Postgraduate\"})\n",
    "\n",
    "#For clarity\n",
    "data=data.rename(columns={\"MntWines\": \"Wines\",\"MntFruits\":\"Fruits\",\"MntMeatProducts\":\"Meat\",\"MntFishProducts\":\"Fish\",\"MntSweetProducts\":\"Sweets\",\"MntGoldProds\":\"Gold\"})\n",
    "\n",
    "#Dropping some of the redundant features\n",
    "to_drop = [\"Marital_Status\", \"Dt_Customer\", \"Z_CostContact\", \"Z_Revenue\", \"Year_Birth\", \"ID\"]\n",
    "data = data.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have some new features let's have a look at the data's stats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T04:12:15.401232Z",
     "iopub.status.busy": "2021-10-08T04:12:15.400938Z",
     "iopub.status.idle": "2021-10-08T04:12:15.478487Z",
     "shell.execute_reply": "2021-10-08T04:12:15.477603Z",
     "shell.execute_reply.started": "2021-10-08T04:12:15.401193Z"
    }
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above stats show some discrepancies in mean Income and Age and max Income and age.\n",
    "\n",
    "Do note that  max-age is 128 years, As I calculated the age that would be today (i.e. 2021) and the data is old.\n",
    "\n",
    "I must take a look at the broader view of the data. \n",
    "I will plot some of the selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T04:12:15.48015Z",
     "iopub.status.busy": "2021-10-08T04:12:15.479912Z",
     "iopub.status.idle": "2021-10-08T04:12:24.092248Z",
     "shell.execute_reply": "2021-10-08T04:12:24.091575Z",
     "shell.execute_reply.started": "2021-10-08T04:12:15.480124Z"
    }
   },
   "outputs": [],
   "source": [
    "#To plot some selected features \n",
    "#Setting up colors prefrences\n",
    "sns.set(rc={\"axes.facecolor\":\"#FFF9ED\",\"figure.facecolor\":\"#FFF9ED\"})\n",
    "pallet = [\"#682F2F\", \"#9E726F\", \"#D6B2B1\", \"#B9C0C9\", \"#9F8A78\", \"#F3AB60\"]\n",
    "cmap = colors.ListedColormap([\"#682F2F\", \"#9E726F\", \"#D6B2B1\", \"#B9C0C9\", \"#9F8A78\", \"#F3AB60\"])\n",
    "#Plotting following features\n",
    "To_Plot = [ \"Income\", \"Recency\", \"Customer_For\", \"Age\", \"Spent\", \"Is_Parent\"]\n",
    "print(\"Reletive Plot Of Some Selected Features: A Data Subset\")\n",
    "plt.figure()\n",
    "sns.pairplot(data[To_Plot], hue= \"Is_Parent\",palette= ([\"#682F2F\",\"#F3AB60\"]))\n",
    "#Taking hue \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, there are a few outliers in the Income and Age features. \n",
    "I will be deleting the outliers in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T04:12:24.093983Z",
     "iopub.status.busy": "2021-10-08T04:12:24.093559Z",
     "iopub.status.idle": "2021-10-08T04:12:24.102146Z",
     "shell.execute_reply": "2021-10-08T04:12:24.10103Z",
     "shell.execute_reply.started": "2021-10-08T04:12:24.093947Z"
    }
   },
   "outputs": [],
   "source": [
    "#Dropping the outliers by setting a cap on Age and income. \n",
    "data = data[(data[\"Age\"]<90)]\n",
    "data = data[(data[\"Income\"]<600000)]\n",
    "print(\"The total number of data-points after removing the outliers are:\", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let us look at the correlation amongst the features. \n",
    "(Excluding the categorical attributes at this point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T04:12:24.103771Z",
     "iopub.status.busy": "2021-10-08T04:12:24.103513Z",
     "iopub.status.idle": "2021-10-08T04:12:28.362244Z",
     "shell.execute_reply": "2021-10-08T04:12:28.361309Z",
     "shell.execute_reply.started": "2021-10-08T04:12:24.103737Z"
    }
   },
   "outputs": [],
   "source": [
    "#correlation matrix\n",
    "corrmat= data.corr()\n",
    "plt.figure(figsize=(20,20))  \n",
    "sns.heatmap(corrmat,annot=True, cmap=cmap, center=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is quite clean and the new features have been included. I will proceed to the next step. That is, preprocessing the data. \n",
    "\n",
    "<a id=\"4\"></a>\n",
    "# <p style=\"background-color:#682F2F;font-family:newtimeroman;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\">DATA PREPROCESSING</p>\n",
    "\n",
    "In this section, I will be preprocessing the data to perform clustering operations.\n",
    "\n",
    "**The following steps are applied to preprocess the data:**\n",
    "\n",
    "* Label encoding the categorical features\n",
    "* Scaling the features using the standard scaler \n",
    "* Creating a subset dataframe for dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T04:12:28.363675Z",
     "iopub.status.busy": "2021-10-08T04:12:28.363461Z",
     "iopub.status.idle": "2021-10-08T04:12:28.369803Z",
     "shell.execute_reply": "2021-10-08T04:12:28.368828Z",
     "shell.execute_reply.started": "2021-10-08T04:12:28.36365Z"
    }
   },
   "outputs": [],
   "source": [
    "#Get list of categorical variables\n",
    "s = (data.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "print(\"Categorical variables in the dataset:\", object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T04:12:28.371692Z",
     "iopub.status.busy": "2021-10-08T04:12:28.371419Z",
     "iopub.status.idle": "2021-10-08T04:12:28.390719Z",
     "shell.execute_reply": "2021-10-08T04:12:28.389214Z",
     "shell.execute_reply.started": "2021-10-08T04:12:28.371665Z"
    }
   },
   "outputs": [],
   "source": [
    "#Label Encoding the object dtypes.\n",
    "LE=LabelEncoder()\n",
    "for i in object_cols:\n",
    "    data[i]=data[[i]].apply(LE.fit_transform)\n",
    "    \n",
    "print(\"All features are now numerical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T04:12:28.392542Z",
     "iopub.status.busy": "2021-10-08T04:12:28.39217Z",
     "iopub.status.idle": "2021-10-08T04:12:28.408294Z",
     "shell.execute_reply": "2021-10-08T04:12:28.406909Z",
     "shell.execute_reply.started": "2021-10-08T04:12:28.392454Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating a copy of data\n",
    "ds = data.copy()\n",
    "# creating a subset of dataframe by dropping the features on deals accepted and promotions\n",
    "cols_del = ['AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp1','AcceptedCmp2', 'Complain', 'Response']\n",
    "ds = ds.drop(cols_del, axis=1)\n",
    "#Scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(ds)\n",
    "scaled_ds = pd.DataFrame(scaler.transform(ds),columns= ds.columns )\n",
    "print(\"All features are now scaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T04:12:28.40998Z",
     "iopub.status.busy": "2021-10-08T04:12:28.409695Z",
     "iopub.status.idle": "2021-10-08T04:12:28.436795Z",
     "shell.execute_reply": "2021-10-08T04:12:28.43589Z",
     "shell.execute_reply.started": "2021-10-08T04:12:28.409942Z"
    }
   },
   "outputs": [],
   "source": [
    "#Scaled data to be used for reducing the dimensionality\n",
    "print(\"Dataframe to be used for further modelling:\")\n",
    "scaled_ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "# <p style=\"background-color:#682F2F;font-family:newtimeroman;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\">DIMENSIONALITY REDUCTION</p>\n",
    "In this problem, there are many factors on the basis of which the final classification will be done. These factors are basically attributes or features. The higher the number of features, the harder it is to work with it. Many of these features are correlated, and hence redundant. This is why I will be performing dimensionality reduction on the selected features before putting them through a classifier.  \n",
    "*Dimensionality reduction is the process of reducing the number of random variables under consideration, by obtaining a set of principal variables.* \n",
    "\n",
    "**Principal component analysis (PCA)** is a technique for reducing the dimensionality of such datasets, increasing interpretability but at the same time minimizing information loss.\n",
    "\n",
    "**Steps in this section:**\n",
    "* Dimensionality reduction with PCA\n",
    "* Plotting the reduced dataframe\n",
    "\n",
    "**Dimensionality reduction with PCA**\n",
    "\n",
    "For this project, I will be reducing the dimensions to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T04:12:28.438297Z",
     "iopub.status.busy": "2021-10-08T04:12:28.438067Z",
     "iopub.status.idle": "2021-10-08T04:12:28.496516Z",
     "shell.execute_reply": "2021-10-08T04:12:28.495475Z",
     "shell.execute_reply.started": "2021-10-08T04:12:28.438263Z"
    }
   },
   "outputs": [],
   "source": [
    "#Initiating PCA to reduce dimentions aka features to 3\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(scaled_ds)\n",
    "PCA_ds = pd.DataFrame(pca.transform(scaled_ds), columns=([\"col1\",\"col2\", \"col3\"]))\n",
    "PCA_ds.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T04:12:28.49906Z",
     "iopub.status.busy": "2021-10-08T04:12:28.498425Z",
     "iopub.status.idle": "2021-10-08T04:12:28.809426Z",
     "shell.execute_reply": "2021-10-08T04:12:28.808813Z",
     "shell.execute_reply.started": "2021-10-08T04:12:28.499006Z"
    }
   },
   "outputs": [],
   "source": [
    "#A 3D Projection Of Data In The Reduced Dimension\n",
    "x =PCA_ds[\"col1\"]\n",
    "y =PCA_ds[\"col2\"]\n",
    "z =PCA_ds[\"col3\"]\n",
    "#To plot\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "ax.scatter(x,y,z, c=\"maroon\", marker=\"o\" )\n",
    "ax.set_title(\"A 3D Projection Of Data In The Reduced Dimension\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "# <p style=\"background-color:#682F2F;font-family:newtimeroman;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\">CLUSTERING</p>\n",
    "\n",
    "Now that I have reduced the attributes to three dimensions, I will be performing clustering via Agglomerative clustering. Agglomerative clustering is a hierarchical clustering method.  It involves merging examples until the desired number of clusters is achieved.\n",
    "\n",
    "**Steps involved in the Clustering**\n",
    "* Elbow Method to determine the number of clusters to be formed\n",
    "* Clustering via Agglomerative Clustering\n",
    "* Examining the clusters formed via scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T04:12:28.811458Z",
     "iopub.status.busy": "2021-10-08T04:12:28.810697Z",
     "iopub.status.idle": "2021-10-08T04:12:30.671151Z",
     "shell.execute_reply": "2021-10-08T04:12:30.670434Z",
     "shell.execute_reply.started": "2021-10-08T04:12:28.811409Z"
    }
   },
   "outputs": [],
   "source": [
    "# Quick examination of elbow method to find numbers of clusters to make.\n",
    "print('Elbow Method to determine the number of clusters to be formed:')\n",
    "Elbow_M = KElbowVisualizer(KMeans(), k=10)\n",
    "Elbow_M.fit(PCA_ds)\n",
    "Elbow_M.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-24T12:48:31.555898Z",
     "iopub.status.busy": "2021-09-24T12:48:31.555573Z",
     "iopub.status.idle": "2021-09-24T12:48:31.559969Z",
     "shell.execute_reply": "2021-09-24T12:48:31.559288Z",
     "shell.execute_reply.started": "2021-09-24T12:48:31.55586Z"
    }
   },
   "source": [
    "The above cell indicates that four will be an optimal number of clusters for this data. \n",
    "Next, we will be fitting the Agglomerative Clustering Model to get the final clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T04:12:30.673126Z",
     "iopub.status.busy": "2021-10-08T04:12:30.672666Z",
     "iopub.status.idle": "2021-10-08T04:12:30.827286Z",
     "shell.execute_reply": "2021-10-08T04:12:30.826598Z",
     "shell.execute_reply.started": "2021-10-08T04:12:30.673084Z"
    }
   },
   "outputs": [],
   "source": [
    "#Initiating the Agglomerative Clustering model \n",
    "AC = AgglomerativeClustering(n_clusters=4)\n",
    "# fit model and predict clusters\n",
    "yhat_AC = AC.fit_predict(PCA_ds)\n",
    "PCA_ds[\"Clusters\"] = yhat_AC\n",
    "#Adding the Clusters feature to the orignal dataframe.\n",
    "data[\"Clusters\"]= yhat_AC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To examine the clusters formed let's have a look at the 3-D distribution of the clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T04:12:30.828955Z",
     "iopub.status.busy": "2021-10-08T04:12:30.82827Z",
     "iopub.status.idle": "2021-10-08T04:12:31.154363Z",
     "shell.execute_reply": "2021-10-08T04:12:31.153018Z",
     "shell.execute_reply.started": "2021-10-08T04:12:30.828912Z"
    }
   },
   "outputs": [],
   "source": [
    "#Plotting the clusters\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = plt.subplot(111, projection='3d', label=\"bla\")\n",
    "ax.scatter(x, y, z, s=40, c=PCA_ds[\"Clusters\"], marker='o', cmap = cmap )\n",
    "ax.set_title(\"The Plot Of The Clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a>\n",
    "# <p style=\"background-color:#682F2F;font-family:newtimeroman;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\">EVALUATING MODELS</p>\n",
    "\n",
    "Since this is an unsupervised clustering. We do not have a tagged feature to evaluate or score our model. The purpose of this section is to study the patterns in the clusters formed and determine the nature of the clusters' patterns. \n",
    "\n",
    "For that, we will be having a look at the data in light of clusters via exploratory data analysis and drawing conclusions. \n",
    "\n",
    "**Firstly, let us have a look at the group distribution of clustring**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T04:12:31.157327Z",
     "iopub.status.busy": "2021-10-08T04:12:31.156307Z",
     "iopub.status.idle": "2021-10-08T04:12:31.385307Z",
     "shell.execute_reply": "2021-10-08T04:12:31.384283Z",
     "shell.execute_reply.started": "2021-10-08T04:12:31.157287Z"
    }
   },
   "outputs": [],
   "source": [
    "#Plotting countplot of clusters\n",
    "pal = [\"#682F2F\",\"#B9C0C9\", \"#9F8A78\",\"#F3AB60\"]\n",
    "pl = sns.countplot(x=data[\"Clusters\"], palette= pal)\n",
    "pl.set_title(\"Distribution Of The Clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clusters seem to be fairly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T04:12:31.389468Z",
     "iopub.status.busy": "2021-10-08T04:12:31.389208Z",
     "iopub.status.idle": "2021-10-08T04:12:31.818333Z",
     "shell.execute_reply": "2021-10-08T04:12:31.817544Z",
     "shell.execute_reply.started": "2021-10-08T04:12:31.38944Z"
    }
   },
   "outputs": [],
   "source": [
    "pl = sns.scatterplot(data = data,x=data[\"Spent\"], y=data[\"Income\"],hue=data[\"Clusters\"], palette= pal)\n",
    "pl.set_title(\"Cluster's Profile Based On Income And Spending\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Income vs  spending plot shows the clusters pattern**\n",
    "* group 0: high spending & average income\n",
    "* group 1: high spending & high income\n",
    "* group 2: low spending & low income \n",
    "* group 3: high spending & low income  \n",
    "\n",
    "Next, I will be looking at the detailed distribution of clusters as per the various products in the data. Namely: Wines, Fruits, Meat, Fish, Sweets and Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T04:12:31.819769Z",
     "iopub.status.busy": "2021-10-08T04:12:31.819474Z",
     "iopub.status.idle": "2021-10-08T04:12:36.276548Z",
     "shell.execute_reply": "2021-10-08T04:12:36.275576Z",
     "shell.execute_reply.started": "2021-10-08T04:12:31.81967Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "pl=sns.swarmplot(x=data[\"Clusters\"], y=data[\"Spent\"], color= \"#CBEDDD\", alpha=0.5 )\n",
    "pl=sns.boxenplot(x=data[\"Clusters\"], y=data[\"Spent\"], palette=pal)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "From the above plot, it can be clearly seen that cluster 1 is our biggest set of customers closely followed by cluster 0.\n",
    "We can explore what each cluster is spending on for the targeted marketing strategies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us next explore how did our campaigns do in the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T04:12:36.278041Z",
     "iopub.status.busy": "2021-10-08T04:12:36.277774Z",
     "iopub.status.idle": "2021-10-08T04:12:36.565937Z",
     "shell.execute_reply": "2021-10-08T04:12:36.565035Z",
     "shell.execute_reply.started": "2021-10-08T04:12:36.27801Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating a feature to get a sum of accepted promotions \n",
    "data[\"Total_Promos\"] = data[\"AcceptedCmp1\"]+ data[\"AcceptedCmp2\"]+ data[\"AcceptedCmp3\"]+ data[\"AcceptedCmp4\"]+ data[\"AcceptedCmp5\"]\n",
    "#Plotting count of total campaign accepted.\n",
    "plt.figure()\n",
    "pl = sns.countplot(x=data[\"Total_Promos\"],hue=data[\"Clusters\"], palette= pal)\n",
    "pl.set_title(\"Count Of Promotion Accepted\")\n",
    "pl.set_xlabel(\"Number Of Total Accepted Promotions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There has not been an overwhelming response to the campaigns so far. Very few participants overall. Moreover, no one part take in all 5 of them. Perhaps better-targeted and well-planned campaigns are required to boost sales. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T04:12:36.567218Z",
     "iopub.status.busy": "2021-10-08T04:12:36.567009Z",
     "iopub.status.idle": "2021-10-08T04:12:36.806254Z",
     "shell.execute_reply": "2021-10-08T04:12:36.805457Z",
     "shell.execute_reply.started": "2021-10-08T04:12:36.567195Z"
    }
   },
   "outputs": [],
   "source": [
    "#Plotting the number of deals purchased\n",
    "plt.figure()\n",
    "pl=sns.boxenplot(y=data[\"NumDealsPurchases\"],x=data[\"Clusters\"], palette= pal)\n",
    "pl.set_title(\"Number of Deals Purchased\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike campaigns, the deals offered did well. It has best outcome with cluster 0 and cluster 3. \n",
    "However, our star customers cluster 1 are not much into the deals. \n",
    "Nothing seems to attract cluster 2 overwhelmingly \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-10-08T04:12:36.807729Z",
     "iopub.status.busy": "2021-10-08T04:12:36.807424Z",
     "iopub.status.idle": "2021-10-08T04:12:39.973646Z",
     "shell.execute_reply": "2021-10-08T04:12:39.972882Z",
     "shell.execute_reply.started": "2021-10-08T04:12:36.807697Z"
    }
   },
   "outputs": [],
   "source": [
    "#for more details on the purchasing style \n",
    "Places =[\"NumWebPurchases\", \"NumCatalogPurchases\", \"NumStorePurchases\",  \"NumWebVisitsMonth\"] \n",
    "\n",
    "for i in Places:\n",
    "    plt.figure()\n",
    "    sns.jointplot(x=data[i],y = data[\"Spent\"],hue=data[\"Clusters\"], palette= pal)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"8\"></a>\n",
    "# <p style=\"background-color:#682F2F;font-family:newtimeroman;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\">PROFILING</p>\n",
    "\n",
    "Now that we have formed the clusters and looked at their purchasing habits. \n",
    "Let us see who all are there in these clusters. For that, we will be profiling the clusters formed and come to a conclusion about who is our star customer and who needs more attention from the retail store's marketing team.\n",
    "\n",
    "To decide that I will be plotting some of the features that are indicative of the customer's personal traits in light of the cluster they are in. \n",
    "On the basis of the outcomes, I will be arriving at the conclusions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-08T04:12:39.974932Z",
     "iopub.status.busy": "2021-10-08T04:12:39.974688Z",
     "iopub.status.idle": "2021-10-08T04:13:05.313109Z",
     "shell.execute_reply": "2021-10-08T04:13:05.312427Z",
     "shell.execute_reply.started": "2021-10-08T04:12:39.974905Z"
    }
   },
   "outputs": [],
   "source": [
    "Personal = [ \"Kidhome\",\"Teenhome\",\"Customer_For\", \"Age\", \"Children\", \"Family_Size\", \"Is_Parent\", \"Education\",\"Living_With\"]\n",
    "\n",
    "for i in Personal:\n",
    "    plt.figure()\n",
    "    sns.jointplot(x=data[i], y=data[\"Spent\"], hue =data[\"Clusters\"], kind=\"kde\", palette=pal)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points to be noted:**\n",
    "\n",
    "The following information can be deduced about the customers in different clusters.\n",
    "\n",
    "<img src=\"https://github.com/KarnikaKapoor/Files/blob/main/Colorful%20Handwritten%20About%20Me%20Blank%20Education%20Presentation%20(3).png?raw=true\">\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"9\"></a>\n",
    "# <p style=\"background-color:#682F2F;font-family:newtimeroman;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\">CONCLUSION</p>\n",
    "\n",
    "In this project, I performed unsupervised clustering. \n",
    "I did use dimensionality reduction followed by agglomerative clustering. \n",
    "I came up with 4 clusters and further used them in profiling customers in clusters according to their family structures and income/spending. \n",
    "This can be used in planning better marketing strategies. \n",
    "\n",
    "**<span style=\"color:#682F2F;\"> If you liked this Notebook, please do upvote.</span>**\n",
    "\n",
    "**<span style=\"color:#682F2F;\">If you have any questions, feel free to comment!</span>**\n",
    "\n",
    "**<span style=\"color:#682F2F;\"> Best Wishes!</span>**\n",
    "\n",
    "<a id=\"10\"></a>\n",
    "# <p style=\"background-color:#682F2F;font-family:newtimeroman;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\">END</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
